
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8">
<meta name="keywords" content="Jianlong Fu">
<meta name="description" content="Academic Homepage of Jianlong Fu">
<link href="static/css/bootstrap.min.css" media="all" rel="stylesheet">
<link href="static/css/main.css" media="all" rel="stylesheet">
<title>Jianlong Fu</title>
</head>

<body>
<section id ="headinformation" class="sectionwhite">
<table id="tbInformation" width="100%">
    <tr>
        <td width="480"> <h1>Jianlong Fu <font style="font-family:Microsoft JHengHei ">傅建龙</font></h1>
        </td>
        <td rowspan="2" align="right">
            <img src="static/img/JianlongFu2017L.JPG" border="0" height="200">
        </td>
        <tr>
            <td>
                <p><font size="4">Researcher<br>
                    Microsoft Research Asia<br>
                    Beijing, China<br>
                    Email: jianf at microsoft dot com<br>
            </td>
        </tr>
        <tr><td>
                <!--<A href="https://scholar.google.com/citations?user=-WqSwu8AAAAJ&hl=zh-CN&oi=ao" target="_blank">Google Scholar</A>-->
            &nbsp&nbsp&nbsp<A href="https://dblp.uni-trier.de/pers/hd/f/Fu:Jianlong" taget="_blank">dblp</A>
            &nbsp&nbsp&nbsp<A href="https://github.com/Jianlong-Fu" taget="_blank">Github</A>
        </td></tr>
</table>
</section>

<section id="Biography" class="sectiongray">
    <h3> Biography </h3>
    <font size = "normal">
        Jianlong Fu is a Researcher with <a href="https://www.microsoft.com/en-us/research/group/multimedia-search-and-mining/" target="_blank">the Multimedia Search and Mining Group</a>, <a href="https://research.microsoft.com/asia/" target="_blank">Microsoft Research Asia</a>, Beijing, China. His current research interests include <b> computer vision and multimedia content analysis, especially on fine-grained image recognition, vision and language, personal photo experience of browsing, searching, sharing and storytelling</b>. He has shipped core technologies to Microsoft products, including <b> Windows Photo, Bing image search, XiaoIce Chatbot, Microsoft Flower</b>, etc. Jianlong Fu received his Ph.D. degree in pattern recognition and intelligent system from the Institute of Automation, Chinese Academy of Science in 2015.
    <br><br>
</section>

<section id="Highlights" class="sectionwhite">
    <h3> Highlights </h3>
    <font size = "normal">
        2. <b><font color="#FF0000">[NEW] </font>We have got <font color="#FF0000">ACM Multimedia 2018 Best Paper Award</font> for the paper "Beyond Narrative Description: Generating Poetry from Images by Multi-Adversarial Training"!</b><br>
        1. <b><font color="#FF0000">[NEW] </font>IEEE Transactions on PAMI: Special Issue on Fine-Grained Visual Categorization extended to November 30.</b>
        [<a href="static/files/CFP-TPAMISI-s.pdf" target="_blank">PDF</a>]
        <br><br>
    </font>
</section>

<section id="Publications" class="sectiongray">
    <h3> Recent Publications </h3>

<table cellpadding=3 cellspacing=0 width="100%" class="sectiongray" >
<!--papers list start-->

<TR> <TD class="pubindex"><FONT>[14]&nbsp</FONT></TD> <TD STYLE ="VERTICAL-ALIGN: TOP">
<FONT class="pubtitle">Beyond Narrative Description: Generating Poetry from Images by Multi-Adversarial Training. </FONT>
<FONT >Bei Liu, <b>Jianlong Fu</b>, Makoto P. Kato, Masatoshi Yoshikawa. </FONT>
<FONT class="pubbooktitle">arXiv:1804.08473v2 [cs.CV] 25 Apr 2018. </FONT>
<FONT> <a href="https://www.acmmm.org/2018/awards/">ACM Multimedia 2018 Best Paper Award</a> [<a href="https://arxiv.org/abs/1804.08473" target="_blank">arXiv</a>]</FONT>
</TD></TR>


<TR> <TD class="pubindex"><FONT>[13]&nbsp</FONT></TD> <TD STYLE ="VERTICAL-ALIGN: TOP">
<FONT class="pubtitle">DA-GAN: Instance-level Image Translation by Deep Attention Generative Adversarial Network. </FONT>
<FONT >Shuang Ma, <b>Jianlong Fu</b>, Changwen Chen, Tao Mei. </FONT>
<FONT class="pubbooktitle">IEEE Conference on Computer Vision and Pattern Recognition (CVPR) June 18, 2018. </FONT>
<FONT> &nbsp;[<a href="https://arxiv.org/abs/1802.06454" target="_blank">arXiv</a>]</FONT>
</TD></TR>


<TR> <TD class="pubindex"><FONT>[12]&nbsp</FONT></TD> <TD STYLE ="VERTICAL-ALIGN: TOP">
<FONT class="pubtitle">Show, Reward and Tell: Automatic Generation of Narrative Paragraph from Photo Stream by Adversarial Training. </FONT>
<FONT >Jing Wang, <b>Jianlong Fu</b>, Jinhui Tang, Zechao Li, Tao Mei. </FONT>
<FONT class="pubbooktitle">AAAI Conference on Artificial Intelligence (AAAI), 2018. February 2, 2018. </FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/publication/show-reward-tell-automatic-generation-narrative-paragraph-photo-stream-adversarial-training/" target="_blank">Abstract</a>]</FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/11/AAAI2018_Jing_CameraReady_V3-1.pdf" target="_blank">PDF</a>]</FONT>
</TD></TR>


<TR> <TD class="pubindex"><FONT>[11]&nbsp</FONT></TD> <TD STYLE ="VERTICAL-ALIGN: TOP">
<FONT class="pubtitle">Self-view Grounding Given a Narrated 360 Video. </FONT>
<FONT >Shih-Han Chou, Yi-Chun Chen, Kuo-Hao Zeng, Hou-Ning Hu, <b>Jianlong Fu</b>, Min Sun. </FONT>
<FONT class="pubbooktitle">AAAI Conference on Artificial Intelligence February 1, 2018. </FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/publication/self-view-grounding-given-narrated-360-video/" target="_blank">Abstract</a>]</FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/11/AAAI_CameraReady_finalversion.pdf" target="_blank">PDF</a>]</FONT>
</TD></TR>


<TR> <TD class="pubindex"><FONT>[10]&nbsp</FONT></TD> <TD STYLE ="VERTICAL-ALIGN: TOP">
<FONT class="pubtitle">Learning Multi-Attention Convolutional Neural Network for Fine-Grained Image Recognition (ICCV 2017 Oral). </FONT>
<FONT >Heliang Zheng, <b>Jianlong Fu</b>, Tao Mei, Jiebo Luo. </FONT>
<FONT class="pubbooktitle">IEEE International Conference on Computer Vision (ICCV) October 24, 2017. </FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/publication/learning-multi-attention-convolutional-neural-network-fine-grained-image-recognition/" target="_blank">Abstract</a>]</FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/10/1793.pdf" target="_blank">PDF</a>]</FONT>
</TD></TR>


<TR> <TD class="pubindex"><FONT>[9]&nbsp</FONT></TD> <TD STYLE ="VERTICAL-ALIGN: TOP">
<FONT class="pubtitle">Searching Personal Photos on the Phone with Instant Visual Query Suggestion and Joint Text-Image Hashing. </FONT>
<FONT >Zhaoyang Zeng, <b>Jianlong Fu</b>, Hongyang Chao, Tao Mei. </FONT>
<FONT class="pubbooktitle">ACM International Conference on Multimedia (ACM Multimedia) October 24, 2017. </FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/publication/searching-personal-photos-phone-instant-visual-qery-suggestion-joint-text-image-hashing/" target="_blank">Abstract</a>]</FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/11/coi105-zengA.pdf" target="_blank">PDF</a>]</FONT>
</TD></TR>


<TR> <TD class="pubindex"><FONT>[8]&nbsp</FONT></TD> <TD STYLE ="VERTICAL-ALIGN: TOP">
<FONT class="pubtitle">Show, Adapt and Tell: Adversarial Training of Cross-domain Image Captioner. </FONT>
<FONT >Tseng-Hung Chen, Yuan-Hong Liao, Ching-Yao Chuang, Wan-Ting Hsu, <b>Jianlong Fu</b>, Min Sun. </FONT>
<FONT class="pubbooktitle">IEEE International Conference on Computer Vision (ICCV) October 24, 2017. </FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/publication/show-adapt-tell-adversarial-training-cross-domain-image-captioner/" target="_blank">Abstract</a>]</FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/11/show.adapt_.tell_.pdf" target="_blank">PDF</a>]</FONT>
</TD></TR>


<TR> <TD class="pubindex"><FONT>[7]&nbsp</FONT></TD> <TD STYLE ="VERTICAL-ALIGN: TOP">
<FONT class="pubtitle">Advances in deep learning approaches for image tagging. </FONT>
<FONT ><b>Jianlong Fu</b>, Yong Rui. </FONT>
<FONT class="pubbooktitle">APSIPA Transactions on Signal and Information Processing Cambridge University Press October 5, 2017. </FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/publication/advances-deep-learning-approaches-image-tagging/" target="_blank">Abstract</a>]</FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/11/advances_in_deep_learning_approaches_for_image_tagging.pdf" target="_blank">PDF</a>]</FONT>
</TD></TR>


<TR> <TD class="pubindex"><FONT>[6]&nbsp</FONT></TD> <TD STYLE ="VERTICAL-ALIGN: TOP">
<FONT class="pubtitle">Multi-level Attention Networks for Visual Question Answering. </FONT>
<FONT >Dongfei Yu, <b>Jianlong Fu</b>, Yong Rui, Tao Mei. </FONT>
<FONT class="pubbooktitle">IEEE Conference on Computer Vision and Pattern Recognition (CVPR) July 21, 2017. </FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/publication/multi-level-attention-networks-visual-question-answering/" target="_blank">Abstract</a>]</FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/06/Multi-level-Attention-Networks-for-Visual-Question-Answering.pdf" target="_blank">PDF</a>]</FONT>
</TD></TR>


<TR> <TD class="pubindex"><FONT>[5]&nbsp</FONT></TD> <TD STYLE ="VERTICAL-ALIGN: TOP">
<FONT class="pubtitle">Look Closer to See Better: Recurrent Attention Convolutional Neural Network for Fine-grained Image Recognition (CVPR 2017 Oral). </FONT>
<FONT ><b>Jianlong Fu</b>, Heliang Zheng, Tao Mei. </FONT>
<FONT class="pubbooktitle">IEEE Conference on Computer Vision and Pattern Recognition (CVPR) July 21, 2017. </FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/publication/look-closer-see-better-recurrent-attention-convolutional-neural-network-fine-grained-image-recognition/" target="_blank">Abstract</a>]</FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/07/Look-Closer-to-See-Better-Recurrent-Attention-Convolutional-Neural-Network-for-Fine-grained-Image-Recognition.pdf" target="_blank">PDF</a>]</FONT>
</TD></TR>


<TR> <TD class="pubindex"><FONT>[4]&nbsp</FONT></TD> <TD STYLE ="VERTICAL-ALIGN: TOP">
<FONT class="pubtitle">Let Your Photos Talk: Generating Narrative Paragraph for Photo Stream via Bidirectional Attention Recurrent Neural Networks. </FONT>
<FONT >Yu Liu, <b>Jianlong Fu</b>, Tao Mei, Chang Wen Chen. </FONT>
<FONT class="pubbooktitle">AAAI Conference on Artificial Intelligence February 1, 2017. </FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/publication/let-photos-talk-generating-narrative-paragraph-photo-stream-via-bidirectional-attention-recurrent-neural-networks/" target="_blank">Abstract</a>]</FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/AAAI2017_YU_CameraReady_V2.pdf" target="_blank">PDF</a>]</FONT>
</TD></TR>


<TR> <TD class="pubindex"><FONT>[3]&nbsp</FONT></TD> <TD STYLE ="VERTICAL-ALIGN: TOP">
<FONT class="pubtitle">Beyond Object Recognition: Visual Sentiment Analysis with Deep Coupled Adjective and Noun Neural Networks. </FONT>
<FONT >Jingwen Wang, <b>Jianlong Fu</b>, Yong Xu, Tao Mei. </FONT>
<FONT class="pubbooktitle">International Joint Conference on Artificial Intelligence (IJCAI) August 4, 2016. </FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/publication/beyond-object-recognition-visual-sentiment-analysis-with-deep-coupled-adjective-and-noun-neural-networks/" target="_blank">Abstract</a>]</FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/08/ijcai16.pdf" target="_blank">PDF</a>]</FONT>
</TD></TR>


<TR> <TD class="pubindex"><FONT>[2]&nbsp</FONT></TD> <TD STYLE ="VERTICAL-ALIGN: TOP">
<FONT class="pubtitle">Relaxing from Vocabulary: Robust Weakly-Supervised Deep Learning for Vocabulary-Free Image Tagging. </FONT>
<FONT ><b>Jianlong Fu</b>, Yue Wu, Tao Mei, Jinqiao Wang, Hanqing Lu, Yong Rui. </FONT>
<FONT class="pubbooktitle">IEEE International Conference on Computer Vision December 1, 2015. </FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/publication/relaxing-from-vocabulary-robust-weakly-supervised-deep-learning-for-vocabulary-free-image-tagging/" target="_blank">Abstract</a>]</FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/04/1544.pdf" target="_blank">PDF</a>]</FONT>
</TD></TR>


<TR> <TD class="pubindex"><FONT>[1]&nbsp</FONT></TD> <TD STYLE ="VERTICAL-ALIGN: TOP">
<FONT class="pubtitle">Tagging Personal Photos with Transfer Deep Learning. </FONT>
<FONT ><b>Jianlong Fu</b>, Tao Mei, Kuiyuan Yang, Hanqing Lu, Yong Rui. </FONT>
<FONT class="pubbooktitle">International World Wide Web conference (WWW) May 6, 2015. </FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/publication/tagging-personal-photos-with-transfer-deep-learning-3/" target="_blank">Abstract</a>]</FONT>
<FONT> &nbsp;[<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/08/deepTaggingwww2015_cameraReady.pdf" target="_blank">PDF</a>]</FONT>
</TD></TR>

<!--papers list end-->
</table>

<br>
</section>

</body>
